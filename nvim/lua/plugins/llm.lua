return function(use) end
-- return function(use)
-- 	use({
-- 		"huggingface/llm.nvim",
-- 		config = function()
-- 			-- require("llm").setup({
-- 			-- 	backend = "ollama",
-- 			-- 	model = "qwen2.5-coder:3b",
-- 			-- 	url = "http://localhost:11434/api/generate",
-- 			-- 	tokens_to_clear = { "<EOT>" },
-- 			-- 	fim = {
-- 			-- 		enabled = true,
-- 			-- 		prefix = "<PRE> ",
-- 			-- 		middle = " <MID>",
-- 			-- 		suffix = " <SUF>",
-- 			-- 	},
-- 			-- 	request_body = {
-- 			-- 		raw = true,
-- 			-- 		options = {
-- 			-- 			num_predict = 128,
-- 			-- 			temperature = 0.2,
-- 			-- 			stop = { "<EOT>", "\n\n" },
-- 			-- 		},
-- 			-- 	},
-- 			-- 	context_window = 4096,
-- 			-- 	debounce_ms = 150,
-- 			-- 	accept_keymap = "<C-y>",
-- 			-- 	dismiss_keymap = "<C-n>",
-- 			-- 	enable_suggestions_on_startup = false,
-- 			-- 	enable_suggestions_on_files = "*",
-- 			-- })
-- 			--
-- 			-- -- Manual trigger keybindings
-- 			-- vim.keymap.set("i", "<C-l>", function()
-- 			-- 	require("llm").suggest()
-- 			-- end, { desc = "LLM suggest" })
--
-- 			require("llm").setup({
-- 				backend = "ollama",
-- 				model = "qwen2.5-coder:3b",
-- 				url = "http://localhost:11434/api/generate",
-- 				tokens_to_clear = { "<|endoftext|>" }, -- tokens to remove from the model's output
-- 				-- parameters that are added to the request body, values are arbitrary, you can set any field:value pair here it will be passed as is to the backend
-- 				request_body = {
-- 					parameters = {
-- 						max_new_tokens = 60,
-- 						temperature = 0.2,
-- 						top_p = 0.95,
-- 					},
-- 				},
-- 				-- set this if the model supports fill in the middle
-- 				fim = {
-- 					enabled = true,
-- 					prefix = "<fim_prefix>",
-- 					middle = "<fim_middle>",
-- 					suffix = "<fim_suffix>",
-- 				},
-- 				debounce_ms = 150,
-- 				accept_keymap = "<Tab>",
-- 				dismiss_keymap = "<S-Tab>",
-- 				tls_skip_verify_insecure = false,
-- 				-- llm-ls configuration, cf llm-ls section
-- 				lsp = {
-- 					bin_path = nil,
-- 					host = nil,
-- 					port = nil,
-- 					cmd_env = nil, -- or { LLM_LOG_LEVEL = "DEBUG" } to set the log level of llm-ls
-- 					version = "0.5.3",
-- 				},
-- 				tokenizer = nil, -- cf Tokenizer paragraph
-- 				context_window = 1024, -- max number of tokens for the context window
-- 				enable_suggestions_on_startup = true,
-- 				enable_suggestions_on_files = "*", -- pattern matching syntax to enable suggestions on specific files, either a string or a list of strings
-- 				disable_url_path_completion = false, -- cf Backend
-- 			})
--
-- 			vim.keymap.set("i", "<C-l>", function()
-- 				require("llm.completion").lsp_suggest()
-- 			end, { noremap = true, silent = true })
-- 		end,
-- 	})
-- end
